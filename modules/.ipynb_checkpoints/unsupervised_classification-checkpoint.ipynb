{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Unsupervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Get Vader data for sentiment analysis\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon') \n",
    "\n",
    "# dictionary of colours for making nice plots later\n",
    "PARTY_COLOURS = {'before': '#E91D0E', 'after': '#00A6EF'}\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "def scatter(x, colors):\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    ax.scatter(x[(colors==0),0], x[(colors==0),1], c=PARTY_COLOURS['before'], label='before', alpha=0.5)\n",
    "    ax.scatter(x[(colors==1),0], x[(colors==1),1], c=PARTY_COLOURS['after'], label='after', alpha=0.5)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    plt.legend()\n",
    "    \n",
    "    return f, ax\n",
    "\n",
    "# dimension reduction algorithms can be pretty slow, so let's work with a sample\n",
    "# try on the whole data set if you want!\n",
    "\n",
    "df = df1sentence_sentences_classification\n",
    "#df = df_selection_50_50_balanced\n",
    "\n",
    "df = df_documents_all                  #1.1\n",
    "df = df_documents_50_50_balanced       #1.3\n",
    "df = df_documents_all_3sentences       #2.1\n",
    "df = df_documents_50_50_balanced_3sentences #3.3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_before = df.loc[df['before_retraction'] == 1, ['sentences_citing', 'before_retraction']]#.sample(500)\n",
    "sample_after = df.loc[df['before_retraction'] == 0, ['sentences_citing', 'before_retraction']]#.sample(500)\n",
    "sample = sample_before.append(sample_after)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(sample['sentences_citing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(tfidf_vectors.toarray())\n",
    "\n",
    "pca_vectors = pca.transform(tfidf_vectors.toarray())\n",
    "\n",
    "scatter(pca_vectors, sample['before_retraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# we have suggested some parameters below, feel free to experiment\n",
    "tsne = TSNE(perplexity = 800, random_state = 42)\n",
    "\n",
    "tsne_vectors = tsne.fit_transform(tfidf_vectors.toarray())\n",
    "\n",
    "scatter(tsne_vectors, sample[\"before_retraction\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
